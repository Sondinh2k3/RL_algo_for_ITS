{
  "network": "grid4x4",
  "num_episodes": 1,
  "mean_reward": -285.6256944444442,
  "std_reward": 0.0,
  "min_reward": -285.6256944444442,
  "max_reward": -285.6256944444442,
  "mean_length": 89.0,
  "episode_rewards": [
    -285.6256944444442
  ],
  "episode_lengths": [
    89
  ],
  "per_agent_stats": {
    "A0": {
      "mean_reward": -25.829629629629633,
      "std_reward": 0.0
    },
    "A1": {
      "mean_reward": -22.873379629629625,
      "std_reward": 0.0
    },
    "A2": {
      "mean_reward": -16.01875,
      "std_reward": 0.0
    },
    "A3": {
      "mean_reward": -22.781712962962967,
      "std_reward": 0.0
    },
    "B0": {
      "mean_reward": -21.92106481481482,
      "std_reward": 0.0
    },
    "B1": {
      "mean_reward": -16.230092592592595,
      "std_reward": 0.0
    },
    "B2": {
      "mean_reward": -26.21412037037037,
      "std_reward": 0.0
    },
    "B3": {
      "mean_reward": -11.17060185185185,
      "std_reward": 0.0
    },
    "C0": {
      "mean_reward": -12.889351851851847,
      "std_reward": 0.0
    },
    "C1": {
      "mean_reward": -15.784490740740738,
      "std_reward": 0.0
    },
    "C2": {
      "mean_reward": -14.081018518518523,
      "std_reward": 0.0
    },
    "C3": {
      "mean_reward": -10.506018518518516,
      "std_reward": 0.0
    },
    "D0": {
      "mean_reward": -15.343981481481482,
      "std_reward": 0.0
    },
    "D1": {
      "mean_reward": -26.68518518518519,
      "std_reward": 0.0
    },
    "D2": {
      "mean_reward": -11.567824074074073,
      "std_reward": 0.0
    },
    "D3": {
      "mean_reward": -15.728472222222218,
      "std_reward": 0.0
    }
  }
}