{
  "network": "grid4x4",
  "num_episodes": 1,
  "mean_reward": -490.94833333333366,
  "std_reward": 0.0,
  "min_reward": -490.94833333333366,
  "max_reward": -490.94833333333366,
  "mean_length": 67.0,
  "episode_rewards": [
    -490.94833333333366
  ],
  "episode_lengths": [
    67
  ],
  "per_agent_stats": {
    "A0": {
      "mean_reward": -33.60041666666667,
      "std_reward": 0.0
    },
    "A1": {
      "mean_reward": -31.221666666666675,
      "std_reward": 0.0
    },
    "A2": {
      "mean_reward": -26.936249999999998,
      "std_reward": 0.0
    },
    "A3": {
      "mean_reward": -32.615000000000016,
      "std_reward": 0.0
    },
    "B0": {
      "mean_reward": -36.00666666666666,
      "std_reward": 0.0
    },
    "B1": {
      "mean_reward": -38.64208333333334,
      "std_reward": 0.0
    },
    "B2": {
      "mean_reward": -32.84416666666666,
      "std_reward": 0.0
    },
    "B3": {
      "mean_reward": -27.170000000000005,
      "std_reward": 0.0
    },
    "C0": {
      "mean_reward": -20.583750000000006,
      "std_reward": 0.0
    },
    "C1": {
      "mean_reward": -31.87708333333334,
      "std_reward": 0.0
    },
    "C2": {
      "mean_reward": -32.02833333333334,
      "std_reward": 0.0
    },
    "C3": {
      "mean_reward": -24.29625,
      "std_reward": 0.0
    },
    "D0": {
      "mean_reward": -30.712916666666676,
      "std_reward": 0.0
    },
    "D1": {
      "mean_reward": -40.86500000000001,
      "std_reward": 0.0
    },
    "D2": {
      "mean_reward": -23.617916666666662,
      "std_reward": 0.0
    },
    "D3": {
      "mean_reward": -27.93083333333334,
      "std_reward": 0.0
    }
  }
}